# Teacher Model Training Configuration

data:
  train_path: data/train.json
  dev_path: data/dev.json
  test_path: data/test.json
  max_seq_length: 512
  num_workers: 4

model:
  encoder_name: bert-base-chinese
  num_labels: 12
  dropout: 0.1

training:
  encoder_lr: 2.0e-5
  task_lr: 4.0e-5
  batch_size: 32
  num_epochs: 2
  warmup_ratio: 0.1
  weight_decay: 0.01
  gradient_clip: 1.0
  patience: 3  # early stopping patience

logging:
  save_dir: checkpoints/teacher
  tensorboard_dir: runs/teacher
  log_every: 100
  eval_every: 1  # evaluate every N epochs
  keep_checkpoint_max: 2  # keep last N checkpoints

device: cuda:1
seed: 42

